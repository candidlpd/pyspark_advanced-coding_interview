{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\pyspark_advanced-coding_interview'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\pyspark_advanced-coding_interview\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate missing date records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+----------+\n",
      "|orderID|customerID|productID| orderdate|\n",
      "+-------+----------+---------+----------+\n",
      "|    101|         1|     1001|2024-10-01|\n",
      "|    102|         1|     1002|2024-10-03|\n",
      "|    103|         2|     1003|2024-10-04|\n",
      "|    104|         2|     1004|2024-10-06|\n",
      "|    105|         3|     1005|2024-10-08|\n",
      "|    106|         3|     1006|2024-10-09|\n",
      "|    107|         4|     1007|2024-10-03|\n",
      "|    108|         4|     1008|2024-10-10|\n",
      "|    109|         5|     1009|2024-10-04|\n",
      "|    110|         6|     1010|2024-10-06|\n",
      "|    111|         1|     1011|2024-10-01|\n",
      "|    114|         4|     1014|2024-10-07|\n",
      "+-------+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"MissingDateRecords\").getOrCreate()\n",
    "\n",
    "# Sample Data\n",
    "data = [\n",
    "    (101, 1, 1001, \"2024-10-01\"),\n",
    "    (102, 1, 1002, \"2024-10-03\"),\n",
    "    (103, 2, 1003, \"2024-10-04\"),\n",
    "    (104, 2, 1004, \"2024-10-06\"),\n",
    "    # New Records\n",
    "    (105, 3, 1005, \"2024-10-08\"),\n",
    "    (106, 3, 1006, \"2024-10-09\"),\n",
    "    (107, 4, 1007, \"2024-10-03\"),\n",
    "    (108, 4, 1008, \"2024-10-10\"),\n",
    "    (109, 5, 1009, \"2024-10-04\"),\n",
    "    (110, 6, 1010, \"2024-10-06\"),\n",
    "    (111, 1, 1011, \"2024-10-01\"),\n",
    "    \n",
    "    (114, 4, 1014, \"2024-10-07\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, [\"orderID\", \"customerID\", \"productID\", \"orderdate\"])\n",
    "\n",
    "# Convert to date format\n",
    "df = df.withColumn(\"orderdate\", col(\"orderdate\").cast(DateType()))\n",
    "\n",
    "# Create Temporary View for Spark SQL\n",
    "df.createOrReplaceTempView(\"orders\")\n",
    "df.cache()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+---------+\n",
      "| orderdate|orderID|customerID|productID|\n",
      "+----------+-------+----------+---------+\n",
      "|2024-10-01|    111|         1|     1011|\n",
      "|2024-10-01|    101|         1|     1001|\n",
      "|2024-10-02|   null|      null|     null|\n",
      "|2024-10-03|    107|         4|     1007|\n",
      "|2024-10-03|    102|         1|     1002|\n",
      "|2024-10-04|    109|         5|     1009|\n",
      "|2024-10-04|    103|         2|     1003|\n",
      "|2024-10-05|   null|      null|     null|\n",
      "|2024-10-06|    110|         6|     1010|\n",
      "|2024-10-06|    104|         2|     1004|\n",
      "|2024-10-07|    114|         4|     1014|\n",
      "|2024-10-08|    105|         3|     1005|\n",
      "|2024-10-09|    106|         3|     1006|\n",
      "|2024-10-10|    108|         4|     1008|\n",
      "+----------+-------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = spark.sql(\"\"\" \n",
    "  \n",
    "  WITH date_range AS (\n",
    "    SELECT explode(sequence(to_date('2024-10-01'), to_date('2024-10-10'), interval 1 day)) AS orderdate\n",
    "),\n",
    "full_data AS (\n",
    "    SELECT dr.orderdate, o.orderID, o.customerID, o.productID\n",
    "    FROM date_range dr\n",
    "    LEFT JOIN orders o ON dr.orderdate = o.orderdate\n",
    ")\n",
    "SELECT * FROM full_data ORDER BY orderdate;\n",
    "              \n",
    "                \n",
    "                \"\"\")\n",
    "\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+---------+\n",
      "| orderdate|orderID|customerID|productID|\n",
      "+----------+-------+----------+---------+\n",
      "|2024-10-01|    111|         1|     1011|\n",
      "|2024-10-01|    101|         1|     1001|\n",
      "|2024-10-02|   null|      null|     null|\n",
      "|2024-10-03|    107|         4|     1007|\n",
      "|2024-10-03|    102|         1|     1002|\n",
      "|2024-10-04|    109|         5|     1009|\n",
      "|2024-10-04|    103|         2|     1003|\n",
      "|2024-10-05|   null|      null|     null|\n",
      "|2024-10-06|    110|         6|     1010|\n",
      "|2024-10-06|    104|         2|     1004|\n",
      "|2024-10-07|    114|         4|     1014|\n",
      "|2024-10-08|    105|         3|     1005|\n",
      "|2024-10-09|    106|         3|     1006|\n",
      "|2024-10-10|    108|         4|     1008|\n",
      "+----------+-------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate date range DataFrame\n",
    "date_range_df = spark.sql(\"SELECT explode(sequence(to_date('2024-10-01'), to_date('2024-10-10'), interval 1 day)) AS orderdate\")\n",
    "\n",
    "# Join original data with date range DataFrame\n",
    "full_data_df = date_range_df.join(df, \"orderdate\", \"left\")\n",
    "\n",
    "# Show the result\n",
    "full_data_df.orderBy(\"orderdate\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
