{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\pyspark_advanced-coding_interview'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\pyspark_advanced-coding_interview\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+----------+\n",
      "|EmployeeID|EmployeeName|Department|  HireDate|\n",
      "+----------+------------+----------+----------+\n",
      "|         1|       Alice|        HR|2023-01-15|\n",
      "|         2|         Bob|        HR|2022-11-20|\n",
      "|         3|     Charlie|        IT|2023-03-05|\n",
      "|         4|       David|        IT|2022-12-25|\n",
      "|         5|         Eve|        IT|2023-06-30|\n",
      "|         6|       Frank|   Finance|2022-10-11|\n",
      "|         7|       Grace|   Finance|2023-08-22|\n",
      "|         8|       Heidi|        HR|2023-02-18|\n",
      "|         9|        Ivan|     Sales|2023-04-10|\n",
      "|        10|        Judy|     Sales|2023-07-01|\n",
      "|        11|       Kevin|     Sales|2022-09-15|\n",
      "|        12|       Laura|        IT|2023-05-20|\n",
      "|        13|     Mallory| Marketing|2022-08-05|\n",
      "|        14|        Niaj| Marketing|2023-07-30|\n",
      "|        15|       Oscar| Marketing|2023-09-10|\n",
      "+----------+------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"EmployeesHiredInLastNMonths\").getOrCreate()\n",
    "\n",
    "# Define schema using StructType and StructField\n",
    "schema = StructType([\n",
    "    StructField(\"EmployeeID\", IntegerType(), True),\n",
    "    StructField(\"EmployeeName\", StringType(), True),\n",
    "    StructField(\"Department\", StringType(), True),\n",
    "    StructField(\"HireDate\", DateType(), True)\n",
    "])\n",
    "\n",
    "# Sample data (EmployeeID, EmployeeName, Department, HireDate)\n",
    "data = [\n",
    "    (1, \"Alice\", \"HR\", datetime.strptime(\"2023-01-15\", \"%Y-%m-%d\").date()),\n",
    "    (2, \"Bob\", \"HR\", datetime.strptime(\"2022-11-20\", \"%Y-%m-%d\").date()),\n",
    "    (3, \"Charlie\", \"IT\", datetime.strptime(\"2023-03-05\", \"%Y-%m-%d\").date()),\n",
    "    (4, \"David\", \"IT\", datetime.strptime(\"2022-12-25\", \"%Y-%m-%d\").date()),\n",
    "    (5, \"Eve\", \"IT\", datetime.strptime(\"2023-06-30\", \"%Y-%m-%d\").date()),\n",
    "    (6, \"Frank\", \"Finance\", datetime.strptime(\"2022-10-11\", \"%Y-%m-%d\").date()),\n",
    "    (7, \"Grace\", \"Finance\", datetime.strptime(\"2023-08-22\", \"%Y-%m-%d\").date()),\n",
    "    (8, \"Heidi\", \"HR\", datetime.strptime(\"2023-02-18\", \"%Y-%m-%d\").date()),\n",
    "    (9, \"Ivan\", \"Sales\", datetime.strptime(\"2023-04-10\", \"%Y-%m-%d\").date()),\n",
    "    (10, \"Judy\", \"Sales\", datetime.strptime(\"2023-07-01\", \"%Y-%m-%d\").date()),\n",
    "    (11, \"Kevin\", \"Sales\", datetime.strptime(\"2022-09-15\", \"%Y-%m-%d\").date()),\n",
    "    (12, \"Laura\", \"IT\", datetime.strptime(\"2023-05-20\", \"%Y-%m-%d\").date()),\n",
    "    (13, \"Mallory\", \"Marketing\", datetime.strptime(\"2022-08-05\", \"%Y-%m-%d\").date()),\n",
    "    (14, \"Niaj\", \"Marketing\", datetime.strptime(\"2023-07-30\", \"%Y-%m-%d\").date()),\n",
    "    (15, \"Oscar\", \"Marketing\", datetime.strptime(\"2023-09-10\", \"%Y-%m-%d\").date())\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to find employees hired in last n months\n",
    "# Register the DataFrame as a temporary table\n",
    "df.createOrReplaceTempView(\"Employees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+--------+\n",
      "|EmployeeID|EmployeeName|Department|HireDate|\n",
      "+----------+------------+----------+--------+\n",
      "+----------+------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the number of months (n)\n",
    "n = 6\n",
    "\n",
    "# Calculate the number of days (approximate)\n",
    "days = n * 30\n",
    "\n",
    "res = spark.sql(f\"\"\"\n",
    "SELECT *\n",
    "FROM Employees\n",
    "WHERE HireDate >= DATE_SUB(CURRENT_DATE(), {days})\n",
    "\"\"\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+--------+\n",
      "|EmployeeID|EmployeeName|Department|HireDate|\n",
      "+----------+------------+----------+--------+\n",
      "+----------+------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date, date_sub\n",
    "\n",
    "# Define the number of months (n)\n",
    "n = 6\n",
    "\n",
    "# Calculate the date n months ago\n",
    "n_months_ago = date_sub(current_date(), n * 30)  # Approximate calculation for months\n",
    "\n",
    "# Filter employees hired in the last n months\n",
    "recent_hires_df = df.filter(df[\"HireDate\"] >= n_months_ago)\n",
    "\n",
    "recent_hires_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+--------+\n",
      "|EmployeeID|EmployeeName|Department|HireDate|\n",
      "+----------+------------+----------+--------+\n",
      "+----------+------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import add_months\n",
    "\n",
    "# Define the number of months (n)\n",
    "n = 6\n",
    "\n",
    "# Filter employees hired in the last n months using add_months\n",
    "recent_hires_exact_df = df.filter(df[\"HireDate\"] >= add_months(current_date(), -n))\n",
    "\n",
    "recent_hires_exact_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import months_between, lit\n",
    "\n",
    "# Filter employees hired within the last n months using months_between\n",
    "recent_hires_months_between_df = df.filter(months_between(current_date(), df[\"HireDate\"]) <= n)\n",
    "recent_hires_months_between_df.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
