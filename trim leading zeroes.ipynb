{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trim leading zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\pyspark_advanced-coding_interview\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\pyspark_advanced-coding_interview\")\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session with optimized settings\n",
    "spark = (\n",
    "    SparkSession.builder \n",
    "    .appName(\"OptimizedLocalSpark\") \n",
    "    .config(\"spark.driver.memory\", \"8g\")        \n",
    "    .config(\"spark.executor.memory\", \"8g\")    \n",
    "    .config(\"spark.executor.cores\", \"4\")       \n",
    "    .config(\"spark.cores.max\", \"12\")           \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"28\")  \n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "|id |number_string|\n",
      "+---+-------------+\n",
      "|1  |001234       |\n",
      "|2  |0005678      |\n",
      "|3  |012345       |\n",
      "|4  |0000001      |\n",
      "|5  |12345        |\n",
      "|6  |098765       |\n",
      "|7  |000900       |\n",
      "|8  |004500       |\n",
      "|9  |00000        |\n",
      "|10 |007          |\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"TrimLeadingZeroes\").getOrCreate()\n",
    "\n",
    "# Sample Data: Strings with leading zeroes\n",
    "data = [\n",
    "    (1, \"001234\"),\n",
    "    (2, \"0005678\"),\n",
    "    (3, \"012345\"),\n",
    "    (4, \"0000001\"),\n",
    "    (5, \"12345\"),\n",
    "    (6, \"098765\"),\n",
    "    (7, \"000900\"),\n",
    "    (8, \"004500\"),\n",
    "    (9, \"00000\"),\n",
    "    (10, \"007\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, [\"id\", \"number_string\"])\n",
    "\n",
    "# Create a Temporary View for Spark SQL\n",
    "df.createOrReplaceTempView(\"number_table\")\n",
    "\n",
    "# Show the Original DataFrame\n",
    "df.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------------------+\n",
      "| id|number_string|first_zero_position|\n",
      "+---+-------------+-------------------+\n",
      "|  1|       001234|                  1|\n",
      "|  2|      0005678|                  1|\n",
      "|  3|       012345|                  1|\n",
      "|  4|      0000001|                  1|\n",
      "|  5|        12345|                  0|\n",
      "|  6|       098765|                  1|\n",
      "|  7|       000900|                  1|\n",
      "|  8|       004500|                  1|\n",
      "|  9|        00000|                  1|\n",
      "| 10|          007|                  1|\n",
      "+---+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# instr: Returns the position of the first occurrence of 0 in the string. If not found, it returns 0.\n",
    "res = spark.sql(\"\"\" \n",
    "                \n",
    "  SELECT id, number_string, instr(number_string, '0') AS first_zero_position\n",
    "FROM number_table;\n",
    "              \n",
    "                \"\"\")\n",
    "res.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------------------+\n",
      "| id|number_string|first_zero_position|\n",
      "+---+-------------+-------------------+\n",
      "|  1|       001234|                  1|\n",
      "|  2|      0005678|                  1|\n",
      "|  3|       012345|                  1|\n",
      "|  4|      0000001|                  1|\n",
      "|  5|        12345|                  0|\n",
      "|  6|       098765|                  1|\n",
      "|  7|       000900|                  1|\n",
      "|  8|       004500|                  1|\n",
      "|  9|        00000|                  1|\n",
      "| 10|          007|                  1|\n",
      "+---+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# regexp_extract: Extracts everything before the first occurrence of 0. length provides the index.\n",
    "#Conditional Logic: Returns 0 if no zero is found\n",
    "\n",
    "res1 = spark.sql(\"\"\" \n",
    "                \n",
    "SELECT id, number_string, \n",
    "       CASE WHEN number_string RLIKE '0' THEN length(regexp_extract(number_string, '^(.*?)0', 1)) + 1 ELSE 0 END AS first_zero_position\n",
    "FROM number_table;\n",
    "\n",
    "              \n",
    "                \"\"\")\n",
    "res1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------------------+\n",
      "|id |number_string|first_zero_position|\n",
      "+---+-------------+-------------------+\n",
      "|1  |001234       |1                  |\n",
      "|2  |0005678      |1                  |\n",
      "|3  |012345       |1                  |\n",
      "|4  |0000001      |1                  |\n",
      "|5  |12345        |0                  |\n",
      "|6  |098765       |1                  |\n",
      "|7  |000900       |1                  |\n",
      "|8  |004500       |1                  |\n",
      "|9  |00000        |1                  |\n",
      "|10 |007          |1                  |\n",
      "+---+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Use rlike and expr to mimic PATINDEX behavior\n",
    "df_patindex = df.withColumn(\"first_zero_position\", \n",
    "                            expr(\"CASE WHEN number_string RLIKE '0' THEN length(regexp_extract(number_string, '^(.*?)0', 1)) + 1 ELSE 0 END\"))\n",
    "\n",
    "df_patindex.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------------------+\n",
      "| id|number_string|first_non_zero_position|\n",
      "+---+-------------+-----------------------+\n",
      "|  1|       001234|                      1|\n",
      "|  2|      0005678|                      1|\n",
      "|  3|       012345|                      1|\n",
      "|  4|      0000001|                      1|\n",
      "|  5|        12345|                      1|\n",
      "|  6|       098765|                      1|\n",
      "|  7|       000900|                      1|\n",
      "|  8|       004500|                      1|\n",
      "|  9|        00000|                      0|\n",
      "| 10|          007|                      1|\n",
      "+---+-------------+-----------------------+\n",
      "\n",
      "+---+-------------+-----------------------+\n",
      "|id |number_string|first_non_zero_position|\n",
      "+---+-------------+-----------------------+\n",
      "|1  |001234       |1                      |\n",
      "|2  |0005678      |1                      |\n",
      "|3  |012345       |1                      |\n",
      "|4  |0000001      |1                      |\n",
      "|5  |12345        |1                      |\n",
      "|6  |098765       |1                      |\n",
      "|7  |000900       |1                      |\n",
      "|8  |004500       |1                      |\n",
      "|9  |00000        |0                      |\n",
      "|10 |007          |1                      |\n",
      "+---+-------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res2 = spark.sql(\"\"\" \n",
    "                \n",
    "SELECT id, number_string, \n",
    "       CASE WHEN number_string RLIKE '[1-9]' THEN length(regexp_extract(number_string, '^(.*?)\\\\d', 1)) + 1 ELSE 0 END AS first_non_zero_position\n",
    "FROM number_table;\n",
    "\n",
    "\n",
    "              \n",
    "                \"\"\")\n",
    "res2.show()\n",
    "\n",
    "\n",
    "df_non_zero_pos = df.withColumn(\"first_non_zero_position\", \n",
    "                                expr(\"CASE WHEN number_string RLIKE '[1-9]' THEN length(regexp_extract(number_string, '^(.*?)\\\\d', 1)) + 1 ELSE 0 END\"))\n",
    "\n",
    "df_non_zero_pos.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
