{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to find First and Last day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\pyspark_advanced-coding_interview'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\pyspark_advanced-coding_interview\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|RecordID|Date      |\n",
      "+--------+----------+\n",
      "|1       |2024-10-01|\n",
      "|2       |2024-10-02|\n",
      "|3       |2024-10-03|\n",
      "|4       |2024-10-05|\n",
      "|5       |2024-10-06|\n",
      "|6       |2024-10-07|\n",
      "|7       |2024-10-08|\n",
      "|8       |2024-10-10|\n",
      "|9       |2024-10-12|\n",
      "|10      |2024-10-14|\n",
      "|11      |2024-10-15|\n",
      "|12      |2024-10-18|\n",
      "|13      |2024-10-20|\n",
      "|14      |2024-10-21|\n",
      "|15      |2024-10-22|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DateType\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"FirstLastDayOfWeek\").getOrCreate()\n",
    "\n",
    "# Define schema using StructType and StructField\n",
    "schema = StructType([\n",
    "    StructField(\"RecordID\", IntegerType(), True),\n",
    "    StructField(\"Date\", DateType(), True)\n",
    "])\n",
    "\n",
    "# Sample data with complex dates\n",
    "data = [\n",
    "    (1, datetime(2024, 10, 1)),\n",
    "    (2, datetime(2024, 10, 2)),\n",
    "    (3, datetime(2024, 10, 3)),\n",
    "    (4, datetime(2024, 10, 5)),\n",
    "    (5, datetime(2024, 10, 6)),\n",
    "    (6, datetime(2024, 10, 7)),\n",
    "    (7, datetime(2024, 10, 8)),\n",
    "    (8, datetime(2024, 10, 10)),\n",
    "    (9, datetime(2024, 10, 12)),\n",
    "    (10, datetime(2024, 10, 14)),\n",
    "    (11, datetime(2024, 10, 15)),\n",
    "    (12, datetime(2024, 10, 18)),\n",
    "    (13, datetime(2024, 10, 20)),\n",
    "    (14, datetime(2024, 10, 21)),\n",
    "    (15, datetime(2024, 10, 22))\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a temporary table\n",
    "df.createOrReplaceTempView(\"Dates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------+\n",
      "|Date      |FirstDayOfWeek     |LastDayOfWeek|\n",
      "+----------+-------------------+-------------+\n",
      "|2024-10-01|2024-09-30 00:00:00|2024-10-06   |\n",
      "|2024-10-02|2024-09-30 00:00:00|2024-10-06   |\n",
      "|2024-10-03|2024-09-30 00:00:00|2024-10-06   |\n",
      "|2024-10-05|2024-09-30 00:00:00|2024-10-06   |\n",
      "|2024-10-06|2024-09-30 00:00:00|2024-10-06   |\n",
      "|2024-10-07|2024-10-07 00:00:00|2024-10-13   |\n",
      "|2024-10-08|2024-10-07 00:00:00|2024-10-13   |\n",
      "|2024-10-10|2024-10-07 00:00:00|2024-10-13   |\n",
      "|2024-10-12|2024-10-07 00:00:00|2024-10-13   |\n",
      "|2024-10-14|2024-10-14 00:00:00|2024-10-20   |\n",
      "|2024-10-15|2024-10-14 00:00:00|2024-10-20   |\n",
      "|2024-10-18|2024-10-14 00:00:00|2024-10-20   |\n",
      "|2024-10-20|2024-10-14 00:00:00|2024-10-20   |\n",
      "|2024-10-21|2024-10-21 00:00:00|2024-10-27   |\n",
      "|2024-10-22|2024-10-21 00:00:00|2024-10-27   |\n",
      "+----------+-------------------+-------------+\n",
      "\n",
      "+----------+--------------+-------------+\n",
      "|Date      |FirstDayOfWeek|LastDayOfWeek|\n",
      "+----------+--------------+-------------+\n",
      "|2024-10-01|2024-09-30    |2024-10-06   |\n",
      "|2024-10-02|2024-09-30    |2024-10-06   |\n",
      "|2024-10-03|2024-09-30    |2024-10-06   |\n",
      "|2024-10-05|2024-09-30    |2024-10-06   |\n",
      "|2024-10-06|2024-10-07    |2024-10-13   |\n",
      "|2024-10-07|2024-10-07    |2024-10-13   |\n",
      "|2024-10-08|2024-10-07    |2024-10-13   |\n",
      "|2024-10-10|2024-10-07    |2024-10-13   |\n",
      "|2024-10-12|2024-10-07    |2024-10-13   |\n",
      "|2024-10-14|2024-10-14    |2024-10-20   |\n",
      "|2024-10-15|2024-10-14    |2024-10-20   |\n",
      "|2024-10-18|2024-10-14    |2024-10-20   |\n",
      "|2024-10-20|2024-10-21    |2024-10-27   |\n",
      "|2024-10-21|2024-10-21    |2024-10-27   |\n",
      "|2024-10-22|2024-10-21    |2024-10-27   |\n",
      "+----------+--------------+-------------+\n",
      "\n",
      "+----------+--------------+-------------+\n",
      "|Date      |FirstDayOfWeek|LastDayOfWeek|\n",
      "+----------+--------------+-------------+\n",
      "|2024-10-01|2024-09-30    |2024-10-06   |\n",
      "|2024-10-02|2024-09-30    |2024-10-06   |\n",
      "|2024-10-03|2024-09-30    |2024-10-06   |\n",
      "|2024-10-05|2024-09-30    |2024-10-06   |\n",
      "|2024-10-06|2024-10-07    |2024-10-13   |\n",
      "|2024-10-07|2024-10-07    |2024-10-13   |\n",
      "|2024-10-08|2024-10-07    |2024-10-13   |\n",
      "|2024-10-10|2024-10-07    |2024-10-13   |\n",
      "|2024-10-12|2024-10-07    |2024-10-13   |\n",
      "|2024-10-14|2024-10-14    |2024-10-20   |\n",
      "|2024-10-15|2024-10-14    |2024-10-20   |\n",
      "|2024-10-18|2024-10-14    |2024-10-20   |\n",
      "|2024-10-20|2024-10-21    |2024-10-27   |\n",
      "|2024-10-21|2024-10-21    |2024-10-27   |\n",
      "|2024-10-22|2024-10-21    |2024-10-27   |\n",
      "+----------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Method 1 Execution\n",
    "query1 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Date, \n",
    "    date_trunc('WEEK', Date) AS FirstDayOfWeek,\n",
    "    date_add(date_trunc('WEEK', Date), 6) AS LastDayOfWeek\n",
    "FROM Dates\n",
    "\"\"\")\n",
    "query1.show(truncate=False)\n",
    "\n",
    "# Method 2 Execution\n",
    "query2 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Date, \n",
    "    date_sub(next_day(Date, 'Sunday'), 6) AS FirstDayOfWeek,\n",
    "    next_day(Date, 'Sunday') AS LastDayOfWeek\n",
    "FROM Dates\n",
    "\"\"\")\n",
    "query2.show(truncate=False)\n",
    "\n",
    "# Method 3 Execution\n",
    "query3 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Date,\n",
    "    date_sub(Date, dayofweek(Date) - 2) AS FirstDayOfWeek,\n",
    "    date_add(Date, 8 - dayofweek(Date)) AS LastDayOfWeek\n",
    "FROM Dates\n",
    "\"\"\")\n",
    "query3.show(truncate=False)\n",
    "\n",
    "# Returns the next Sunday after the given date, which will be treated as the end of the week.\n",
    "# Returns an integer (1 for Sunday, 2 for Monday, etc.)\n",
    "# Returns the first day of the week (Monday) for the specified date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------------+-------------+\n",
      "|RecordID|Date      |FirstDayOfWeek     |LastDayOfWeek|\n",
      "+--------+----------+-------------------+-------------+\n",
      "|1       |2024-10-01|2024-09-30 00:00:00|2024-10-06   |\n",
      "|2       |2024-10-02|2024-09-30 00:00:00|2024-10-06   |\n",
      "|3       |2024-10-03|2024-09-30 00:00:00|2024-10-06   |\n",
      "|4       |2024-10-05|2024-09-30 00:00:00|2024-10-06   |\n",
      "|5       |2024-10-06|2024-09-30 00:00:00|2024-10-06   |\n",
      "|6       |2024-10-07|2024-10-07 00:00:00|2024-10-13   |\n",
      "|7       |2024-10-08|2024-10-07 00:00:00|2024-10-13   |\n",
      "|8       |2024-10-10|2024-10-07 00:00:00|2024-10-13   |\n",
      "|9       |2024-10-12|2024-10-07 00:00:00|2024-10-13   |\n",
      "|10      |2024-10-14|2024-10-14 00:00:00|2024-10-20   |\n",
      "|11      |2024-10-15|2024-10-14 00:00:00|2024-10-20   |\n",
      "|12      |2024-10-18|2024-10-14 00:00:00|2024-10-20   |\n",
      "|13      |2024-10-20|2024-10-14 00:00:00|2024-10-20   |\n",
      "|14      |2024-10-21|2024-10-21 00:00:00|2024-10-27   |\n",
      "|15      |2024-10-22|2024-10-21 00:00:00|2024-10-27   |\n",
      "+--------+----------+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_trunc, date_add\n",
    "\n",
    "# Find the first and last day of the week using date_trunc\n",
    "df_first_last_day = df.withColumn(\"FirstDayOfWeek\", date_trunc(\"week\", \"Date\")) \\\n",
    "                      .withColumn(\"LastDayOfWeek\", date_add(date_trunc(\"week\", \"Date\"), 6))\n",
    "\n",
    "df_first_last_day.show(truncate=False)\n",
    "\n",
    "# Truncates the date to the start of the week (Monday)\n",
    "# Finds the next Sunday after the given date.\n",
    "# Returns an integer representing the day of the week (1 for Sunday, 2 for Monday, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------+-------------+\n",
      "|RecordID|Date      |FirstDayOfWeek|LastDayOfWeek|\n",
      "+--------+----------+--------------+-------------+\n",
      "|1       |2024-10-01|2024-09-30    |2024-10-06   |\n",
      "|2       |2024-10-02|2024-09-30    |2024-10-06   |\n",
      "|3       |2024-10-03|2024-09-30    |2024-10-06   |\n",
      "|4       |2024-10-05|2024-09-30    |2024-10-06   |\n",
      "|5       |2024-10-06|2024-10-07    |2024-10-13   |\n",
      "|6       |2024-10-07|2024-10-07    |2024-10-13   |\n",
      "|7       |2024-10-08|2024-10-07    |2024-10-13   |\n",
      "|8       |2024-10-10|2024-10-07    |2024-10-13   |\n",
      "|9       |2024-10-12|2024-10-07    |2024-10-13   |\n",
      "|10      |2024-10-14|2024-10-14    |2024-10-20   |\n",
      "|11      |2024-10-15|2024-10-14    |2024-10-20   |\n",
      "|12      |2024-10-18|2024-10-14    |2024-10-20   |\n",
      "|13      |2024-10-20|2024-10-21    |2024-10-27   |\n",
      "|14      |2024-10-21|2024-10-21    |2024-10-27   |\n",
      "|15      |2024-10-22|2024-10-21    |2024-10-27   |\n",
      "+--------+----------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import next_day, date_sub\n",
    "\n",
    "# Assuming the week starts on Monday and ends on Sunday\n",
    "df_first_last_day_2 = df.withColumn(\"FirstDayOfWeek\", date_sub(next_day(\"Date\", \"Sunday\"), 6)) \\\n",
    "                        .withColumn(\"LastDayOfWeek\", next_day(\"Date\", \"Sunday\"))\n",
    "\n",
    "df_first_last_day_2.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------+-------------+\n",
      "|RecordID|Date      |FirstDayOfWeek|LastDayOfWeek|\n",
      "+--------+----------+--------------+-------------+\n",
      "|1       |2024-10-01|2024-09-30    |2024-10-06   |\n",
      "|2       |2024-10-02|2024-09-30    |2024-10-06   |\n",
      "|3       |2024-10-03|2024-09-30    |2024-10-06   |\n",
      "|4       |2024-10-05|2024-09-30    |2024-10-06   |\n",
      "|5       |2024-10-06|2024-10-07    |2024-10-13   |\n",
      "|6       |2024-10-07|2024-10-07    |2024-10-13   |\n",
      "|7       |2024-10-08|2024-10-07    |2024-10-13   |\n",
      "|8       |2024-10-10|2024-10-07    |2024-10-13   |\n",
      "|9       |2024-10-12|2024-10-07    |2024-10-13   |\n",
      "|10      |2024-10-14|2024-10-14    |2024-10-20   |\n",
      "|11      |2024-10-15|2024-10-14    |2024-10-20   |\n",
      "|12      |2024-10-18|2024-10-14    |2024-10-20   |\n",
      "|13      |2024-10-20|2024-10-21    |2024-10-27   |\n",
      "|14      |2024-10-21|2024-10-21    |2024-10-27   |\n",
      "|15      |2024-10-22|2024-10-21    |2024-10-27   |\n",
      "+--------+----------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dayofweek, date_sub, date_add\n",
    "\n",
    "# Calculate first and last day of the week based on day of the week\n",
    "df_first_last_day_3 = df.withColumn(\"FirstDayOfWeek\", date_sub(\"Date\", dayofweek(\"Date\") - 2)) \\\n",
    "                        .withColumn(\"LastDayOfWeek\", date_add(\"Date\", 8 - dayofweek(\"Date\")))\n",
    "\n",
    "df_first_last_day_3.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
